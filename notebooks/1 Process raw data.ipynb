{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert and evaluate raw data\n",
    "\n",
    "The convert data contains:\n",
    "\n",
    "- 2 buffer trials in practice, to be ignored\n",
    "- 18 practice trials\n",
    "- 72 trials from the main part\n",
    "\n",
    "each trial response contains:\n",
    "\n",
    "- identification of the two samples in the order of appearance. The format is <letter>_<top half style><bottom half style>, e.g. `a_AD`. There are four styles identified by capital letters A, B, C, D.\n",
    "- whether the top halfs are identical\n",
    "- participant’s response\n",
    "- exposure time for each letter that is derived from practice and different for each participant\n",
    "- response time\n",
    "\n",
    "e.g. `a_AD,a_AD,true, Probably same, 266.7, 2968`.\n",
    "\n",
    "\n",
    "The processed data looks like this:\n",
    "\n",
    "- non-aggregated, one row per trial\n",
    "- aggregated, one row per session\n",
    "\n",
    "### Columns used for indexing\n",
    "\n",
    "A study (StudyID) was conducted in sessions, one session per participant (ParticipantID). Each session consists of a practice and main part. Each of these is made up of trials (TrialID) where two samples are shown to a participant consecutively for a fixed period of time. After that a response is collected. The practice included 20 trials while the main part included 72 trials. There was a simple introductory questionnaire.\n",
    "\n",
    "- `StudyID` (int), “Pilot” vs “Main”\n",
    "- `ParticipantID` (int, 0 and higher) for a session (all trials) completed by one participant\n",
    "- `TestID` (int) 0 refers to practice, 1 refers to the main part\n",
    "- `TrialID` (int, positive) for individual trials, used only in the non-aggregated data\n",
    "\n",
    "### Columns with responses from the introduction\n",
    "\n",
    "- `Training` (str) one of the training categories\n",
    "- `isDesigner` (bool) whether participants belong to one of the categories of designers, based on `Training\n",
    "\n",
    "### Columns with responses from the trials\n",
    "\n",
    "- `First` (str) first sample used\n",
    "- `Second` (str) second sample\n",
    "- `Response` (str) one of: Sure same, Probably same, Sure different\n",
    "- `Correct` (float) whether participant’s response was correct (1.0) or not (0.0) or **mean** of these values in the aggregated data\n",
    "- `ET` (float) exposure time of the samples\n",
    "- `RT` (float) response time or **mean** of response times in the aggregated data\n",
    "- `RTnorm` (float) normalized response time or **mean** of normalized response times in the aggregated data (natural logarithm was applied)\n",
    "\n",
    "### Columns used in aggregated data\n",
    "\n",
    "- all columns above and\n",
    "- `AUC` (float) for recognition tasks only, area under curve of participant’s responses in this task\n",
    "- `AUCnorm` (float) same as `AUC`, but normalized  by 2 x arcsin (√(AUC))\n",
    "- `Correctnorm` (float) same as `Correct`, but normalized by 2 x arcsin (√(AUC))\n",
    "\n",
    "### Other columns\n",
    "\n",
    "- `Date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# set up a DataFrame to collect the processed data\n",
    "columns = [\n",
    "    \"StudyID\", \"ParticipantID\", \"TestID\", \"TrialID\",\n",
    "    \"Training\", \"isDesigner\",\n",
    "    \"First\", \"Second\", \"Composite pair\", \"Congruent pair\", \"Same\", \"Response\", \"Correct\", \"Correct (normalized)\", \"ET\", \"RT\", \"RT (normalized)\", \"Date\",\n",
    "]\n",
    "startDate = datetime.strptime(\"2022-06-03 00:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "d = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization functions and calculation of AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_auc(auc):\n",
    "    \"\"\"\n",
    "    Transform the square root of AUC\n",
    "    using arcsin and multiply by 2.\n",
    "    \"\"\"\n",
    "\n",
    "    return 2 * np.arcsin(np.sqrt(auc))\n",
    "\n",
    "\n",
    "def normalize_rt(rt):\n",
    "    \"\"\"\n",
    "    Tranform RTs\n",
    "    using natural logarithm.\n",
    "    \"\"\"\n",
    "    if rt > 0:\n",
    "        return np.log(rt)\n",
    "\n",
    "\n",
    "def denormalize_auc(aucnorm):\n",
    "    \"\"\"\n",
    "    Transform the normalized AUC back\n",
    "    using a square of the sine value of its half.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.sin(aucnorm / 2) ** 2\n",
    "\n",
    "\n",
    "def denormalize_rt(rtnorm):\n",
    "    \"\"\"\n",
    "    Tranform the normalized RTs back\n",
    "    using the exponential function.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.exp(rtnorm)\n",
    "\n",
    "\n",
    "def cummulative(x):\n",
    "    return [sum(x[0:i+1]) for i in range(len(x))]\n",
    "\n",
    "\n",
    "def get_auc(x, y):\n",
    "    # make cummulative\n",
    "    x, y = cummulative(x), cummulative(y)\n",
    "    # normalize\n",
    "    if max(x) != 0:\n",
    "        x = [xi/max(x) for xi in x]\n",
    "    else:\n",
    "        x = [xi for xi in x]\n",
    "    if max(y) != 0:\n",
    "        y = [yi/max(y) for yi in y]\n",
    "    else:\n",
    "        y = [yi for yi in y]\n",
    "    auc = 0\n",
    "    x1, y1 = 0, 0\n",
    "    for x2, y2 in zip(x, y):\n",
    "        auc += (x2 - x1) * (y1 + y2) / 2\n",
    "        x1, y1 = x2, y2\n",
    "    return auc\n",
    "\n",
    "map_JoL = {\n",
    "    \"very easy to read\": 100,\n",
    "    \"easy to read\": 75,\n",
    "    \"ok\": 50,\n",
    "    \"difficult to read\": 25,\n",
    "    \"very difficult to read\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data from the raw format to stats-ready format\n",
    "\n",
    "The raw format (saved from the website) has all responses from a single participant saved in a single row.\n",
    "The responses for individual trials are saved in columns like “test_1_lexical”.\n",
    "The following code converts this format and saves responses into individual rows.\n",
    "It also deals with some minor format differences as the formatting evolved with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 21068 responses from 229 participants.\n"
     ]
    }
   ],
   "source": [
    "# Warning: this takes quite a while to compute\n",
    "\n",
    "# congruent pairs\n",
    "congruents = [(\"AA\", \"AA\"), (\"AD\", \"AD\"), (\"AD\", \"BC\"), (\"AA\", \"DD\"), (\"BC\", \"AD\"), (\"DD\", \"AA\")]\n",
    "\n",
    "# participant counter (Participant ID)\n",
    "pid = 0\n",
    "# counter for trials within each session of a single participant\n",
    "x = 0\n",
    "for fn in glob.glob(os.path.join(\"..\", \"data\", \"raw-data*.csv\")):\n",
    "    raw = pd.read_csv(fn)\n",
    "    for i, rraw in raw.iterrows():\n",
    "        # collect data that will be shared across all rows\n",
    "        # for one participant\n",
    "        shared = pd.Series(index=d.columns, dtype=\"float64\")\n",
    "        shared[\"StudyID\"] = \"Pilot\"  # default\n",
    "        if \"submissionDate\" in rraw:\n",
    "            submissionDate = datetime.strptime(rraw[\"submissionDate\"], '%Y-%m-%d %H:%M:%S')\n",
    "            if submissionDate > startDate:\n",
    "                shared[\"StudyID\"] = \"Main\"\n",
    "            shared[\"Date\"] = rraw[\"submissionDate\"]\n",
    "        shared[\"ParticipantID\"] = pid\n",
    "        if \"Designer\" in rraw:\n",
    "            shared[\"Training\"] = rraw[\"Designer\"]\n",
    "            # isDesigner is a boolean column to conveniently group designers together\n",
    "            shared[\"isDesigner\"] = (rraw[\"Designer\"] != \"Non-designer\")\n",
    "        for c in rraw.index:\n",
    "            # get values from columns like this: practice_<number of trial> or main_<number of trial>\n",
    "            if c.startswith(\"practice_\") or c.startswith(\"main_\"):\n",
    "                # prefill with shared data\n",
    "                rd = pd.Series(shared)\n",
    "                if c.startswith(\"practice_\"):\n",
    "                    rd[\"TestID\"] =  0\n",
    "                else:\n",
    "                    rd[\"TestID\"] =  1\n",
    "                # get Trial ID from the column name\n",
    "                rd[\"TrialID\"] = int(c.strip().split(\"_\")[-1])\n",
    "                if isinstance(rraw[c], str) and \",\" in rraw[c]:\n",
    "                    # get the first sample, second sample, response, ET, RT from the value in this column\n",
    "                    # e.g. b_AB,b_AD,true, Sure same, 577.8, 3549\n",
    "                    response = rraw[c].strip().split(\",\")\n",
    "                    rd[\"First\"] = response[0].strip()\n",
    "                    rd[\"Second\"] = response[1].strip()\n",
    "                    # type of the pair\n",
    "                    # Composite (e.g. AB, CB) vs Normal (e.g. AA, DD)\n",
    "                    if rd[\"First\"][2] == rd[\"First\"][3]:\n",
    "                        rd[\"Composite pair\"] = False\n",
    "                    else:\n",
    "                        rd[\"Composite pair\"] = True\n",
    "                    # Congruent pair (e.g. AD/AD, AD/BC) vs Incongruent (e.g. AD/BD, AD/AB)\n",
    "                    pair = (rd[\"First\"][2:], rd[\"Second\"][2:])\n",
    "                    if pair in congruents:\n",
    "                        rd[\"Congruent pair\"] = True\n",
    "                    else:\n",
    "                        rd[\"Congruent pair\"] = False\n",
    "                    rd[\"Same\"] = rd[\"First\"][:3] == rd[\"Second\"][:3]  # same letter, same top half style\n",
    "                    rd[\"Response\"] = response[3].strip()\n",
    "                    rd[\"ET\"] = float(response[4].strip())\n",
    "                    rd[\"RT\"] = float(response[5].strip())\n",
    "                    # evaluate response\n",
    "                    rd[\"Correct\"] = 0\n",
    "                    if rd[\"Same\"] and (\"same\" in rd[\"Response\"]):\n",
    "                        rd[\"Correct\"] = 1\n",
    "                    elif (not rd[\"Same\"]) and (\"different\" in rd[\"Response\"]):\n",
    "                        rd[\"Correct\"] = 1\n",
    "                    # normalize\n",
    "                    rd[\"RT (normalized)\"] = normalize_rt(rd[\"RT\"])\n",
    "                    rd[\"Correct (normalized)\"] = normalize_auc(rd[\"Correct\"])\n",
    "                # add a row with this individual trial to the data\n",
    "                d.loc[x] = rd\n",
    "                x += 1\n",
    "        pid += 1\n",
    "# fix types\n",
    "d[\"ParticipantID\"] = d[\"ParticipantID\"].astype(int)\n",
    "d[\"TestID\"] = d[\"TestID\"].astype(\"int\")\n",
    "d.sort_values(\"Date\")\n",
    "\n",
    "print(\"Processed %d responses from %d participants.\" % (len(d), pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data for each participant\n",
    "\n",
    "Calculate AUC and mean RT across all responses, separately for Practice and Main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_results(d_):\n",
    "    \"\"\"\n",
    "    Aggregate data for every (study, test, participant) combination.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = d_.copy()\n",
    "\n",
    "    # remove Practice round\n",
    "    d = d[d[\"TestID\"] == 1]\n",
    "    # focus on Main only\n",
    "    sid = \"Main\"\n",
    "\n",
    "    # Prefill results\n",
    "    # aggregate correct-ness and response times (use mean value)\n",
    "    # keep the rest as is or set NaN value for new columns\n",
    "    result_columns = columns + [\"AUC\", \"AUC (normalized)\"]\n",
    "    agg_columns = {k:\"first\" for k in set(d.columns).intersection(result_columns)}\n",
    "    agg_columns[\"TrialID\"] = \"count\"\n",
    "    agg_columns[\"Correct\"] = \"mean\"\n",
    "    agg_columns[\"Correct (normalized)\"] = \"mean\"\n",
    "    agg_columns[\"RT\"] = \"mean\"\n",
    "    agg_columns[\"RT (normalized)\"] = \"mean\"\n",
    "    results = d.groupby([\"StudyID\", \"ParticipantID\", \"Composite pair\", \"Congruent pair\"]).agg(agg_columns)  # look only at the Main part, ignore the Practice\n",
    "    results = pd.DataFrame(results, columns=result_columns)\n",
    "    results.set_index([\"StudyID\", \"ParticipantID\", \"Composite pair\", \"Congruent pair\"], inplace=True)\n",
    "    \n",
    "    # index for temporary data frames used to calculate the AUC.\n",
    "    responses = [\"Sure same\", \"Probably same\", \"Probably different\", \"Sure different\"]\n",
    "    ix = pd.MultiIndex.from_product([[True, False], responses], names=[\"Same\", \"Response\"])\n",
    "\n",
    "    # Get each part/test separately\n",
    "\n",
    "    for pid in d[d[\"StudyID\"] == sid][\"ParticipantID\"].unique():  # Participant\n",
    "        for composite in (True, False):\n",
    "            for congruent in (True, False):\n",
    "                if not composite and not congruent:\n",
    "                    continue\n",
    "                # Subset the data frame to participant-test combination\n",
    "                dtt = d[(d[\"StudyID\"] == sid) & (d[\"ParticipantID\"] == pid) & (d[\"Composite pair\"] == composite) & (d[\"Congruent pair\"] == congruent)]\n",
    "                \n",
    "                # Calculate the AUC\n",
    "                # the temporary data frame is needed to\n",
    "                # ensure the order in the index is always the same\n",
    "                dg = pd.DataFrame(index=ix)\n",
    "                dg[\"Frequencies\"] = dtt.groupby([\"Same\"])[\"Response\"].value_counts()\n",
    "                dg = dg.fillna(0)\n",
    "                # use frequencies for same/different for the y coordinate in the get_auc function\n",
    "                # use frequencies for participants responses for the x coordinate\n",
    "                freqs = dg[\"Frequencies\"].tolist()\n",
    "                auc = get_auc(freqs[4:], freqs[:4])  # responses to different stimulae go first\n",
    "                results.loc[(sid, pid, composite, congruent), \"AUC\"] = auc\n",
    "                results.loc[(sid, pid, composite, congruent), \"AUC (normalized)\"] = normalize_auc(auc)\n",
    "    return results\n",
    "\n",
    "aggregated = get_agg_results(d)\n",
    "del aggregated[\"First\"]\n",
    "del aggregated[\"Second\"]\n",
    "del aggregated[\"Same\"]\n",
    "del aggregated[\"Response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# save the processed and aggregated data\n",
    "d.to_csv(os.path.join(\"..\", \"data\", \"serial-data.csv\"))\n",
    "aggregated.to_csv(os.path.join(\"..\", \"data\", \"aggregated-data.csv\"))\n",
    "print(\"Successfully saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1eb769a272a60707ecf8893d0d27fd31fc5674a46b8830d0ac07519bbb76b6c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
